[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quarto CRC Book",
    "section": "",
    "text": "Proyek Sains data\nNama : Sadam payoda sabilillah\nNIM : 200411100069\nprint(\"Akurasi Random Forest:\", decision_tree_accuracy)\nprint(\"Akurasi Random Forest:\", random_forest_accuracy)\nprint(\"Akurasi Regresi Logistik:\", logistic_regression_accuracy)\nprint(\"Akurasi Perceptron:\", perceptron_accuracy)\nprint(\"Akurasi neural_network:\", neural_network_accuracy)\n\nAkurasi Random Forest: 0.7142857142857143\nAkurasi Random Forest: 0.7619047619047619\nAkurasi Regresi Logistik: 0.42857142857142855\nAkurasi Perceptron: 0.42857142857142855\nAkurasi neural_network: 0.42857142857142855\nPada akurasi ini adalah paling tinggi di model yang lain, maka saya memilih metode random forest, alasan lainnya mengapa menggunakan Random Forest Dengan mempertimbangkan acak dan menggunakan banyak pohon, Random Forest dapat mengurangi risiko overfitting pada data pelatihan\nimport joblib\n# from sklearn.externals import joblib\njoblib.dump(random_forest_model, 'model_rf.joblib')\n\n['model_rf.joblib']"
  },
  {
    "objectID": "index.html#cirrhosis-patient-survival-prediction",
    "href": "index.html#cirrhosis-patient-survival-prediction",
    "title": "Quarto CRC Book",
    "section": "Cirrhosis Patient Survival Prediction",
    "text": "Cirrhosis Patient Survival Prediction\nCirrhosis Patient Survival Prediction seperti melakukan prediksi kelangsungan hidup pasien yang menderita dengan penyakit sirosis hati. Sirosis hati adalah kondisi medis yang terjadi ketika jaringan hati normal digantikan oleh jaringan parut, yang dapat mempengaruhi fungsi hati secara signifikan. Proses terbentuknya parut di hati, atau sirosis hati, terjadi sebagai respons terhadap kerusakan yang berulang pada sel hati.\n\nUntuk tujuan apa kumpulan data tersebut dibuat?\n\nSirosis terjadi akibat kerusakan hati yang berkepanjangan, sehingga menimbulkan jaringan parut yang luas, sering kali disebabkan oleh kondisi seperti hepatitis atau konsumsi alkohol kronis. Data yang diberikan bersumber dari penelitian Mayo Clinic tentang sirosis bilier primer (PBC) hati yang dilakukan pada tahun 1974 hingga 1984.\n\n-Tujuan mengumpulkan data\nTujuannya apa untuk mengumpulkan data tersebut dan kenapa kita harus mengumpulkan data Cirrhosis Patient Survival Prediction :\n\nMelalui analisis data, peneliti ilmiah dapat mengidentifikasi faktor-faktor risiko apa saja yang berkaitan dengan kelangsungan hidup pasien. Ini dapat mencakup faktor-faktor seperti tingkat keparahan sirosis, komplikasi lainnya, dan respons terhadap pengobatan.\nmenganalisis data untuk membantu djaalam memahami efektivitas berbagai jenis perawatan dan intervensi pada pasien dengan sirosis hati. Hal ini dapat membantu dokter dalam merencanakan perawatan yang lebih efektif dan tepat waktu agar kemungkinan pada kehidupan penderita sironis hati menjadi lebih aman atau akurasi keberlangsungan hiduo menjadi panjang.\ndengan adanya Informasi dataset Cirrhosis Patient Survival Prediction dengan pengidap prognosis sirosis hati dapat digunakan untuk memberikan edukasi kepada masyarakat tentang faktor risiko dan pentingnya deteksi dini. Kesadaran ini dapat meningkatkan upaya pencegahan dan deteksi dini kondisi yang dapat menyebabkan sirosis hati.\n\nDiatas adalah beberapa tujuan pentingnya untuk mengumpulkan data data CDC Diabetes Health Indicator.\n\n\nMengenai dataset pada Cirrhosis Patient Survival Prediction\n\n\n\n\n\n\n\nFitur\nPenjelasan\n\n\n\n\nID\nNomor identifikasi unik untuk setiap pasien.\n\n\nN_Days\nJumlah hari antara pendaftaran dan peristiwa akhir (kematian, transplantasi hati, atau waktu analisis studi pada Juli 1986).\n\n\nStatus\nStatus pasien pada akhir periode pengamatan. Nilai melibatkan C (censored), CL (censored karena transplantasi hati), atau D (kematian).\n\n\nDrug\nJenis obat yang diberikan kepada pasien (D-penicillamine atau plasebo).\n\n\nAge\nUmur pasien pada saat pengamatan awal.\n\n\nSex\nJenis kelamin pasien (M atau F).\n\n\nAscites\nIndikator keberadaan atau tingkat keparahan ascites (penumpukan cairan di rongga perut) Ascites adalah suatu kondisi di mana cairan berlebihan menumpuk dalam rongga perut, antara lapisan organ dalam rongga perut (seperti hati dan usus) dan dinding perut.\n\n\nHepatomegaly\nHepatomegaly adalah istilah medis yang digunakan untuk menggambarkan pembesaran hati. Hati yang sehat memiliki ukuran tertentu, tetapi berbagai kondisi dapat menyebabkan hati menjadi lebih besar dari ukuran normal, Indikator keberadaan atau tingkat hepatomegali (pembesaran hati).\n\n\nSpiders\n“SPIDERS” yang merupakan singkatan dari “Cirrhosis SPiders of the Liver.” Sistem ini dirancang untuk memberikan perkiraan risiko kelangsungan hidup pasien dengan sirosis hati berdasarkan sejumlah parameter klinis dan laboratorium. Indikator keberadaan atau tingkat keparahan spider nevi (pembuluh darah kecil pada kulit, mungkin menjadi tanda sirosis hati).\n\n\nEdema\nEdema adalah suatu kondisi medis yang ditandai oleh penumpukan cairan yang berlebihan di dalam jaringan tubuh, biasanya di ruang interstisial antara sel-sel. Ini dapat menyebabkan pembengkakan atau pembesaran area yang terkena. Indikator keberadaan atau tingkat edema, dengan nilai N (tidak ada edema dan tanpa terapi diuretik), S (edema hadir tanpa diuretik, atau edema yang teratasi oleh diuretik), atau Y (edema meskipun terapi diuretik).\n\n\nBilirubin\nKadar serum bilirubin dalam mg/dl, indikator kerusakan hati.\n\n\nCholesterol\nKadar serum kolesterol dalam mg/dl.\n\n\nAlbumin\nKadar albumin dalam gm/dl, protein yang diproduksi oleh hati.\n\n\nCopper\nKadar tembaga dalam urine (µg/day), indikator gangguan metabolisme tembaga.\n\n\nAlk_Phos\nKadar fosfatase alkali dalam U/liter, indikator kerusakan hati atau masalah tulang.\n\n\nSGOT\nTes darah SGOT sering dilakukan sebagai bagian dari panel fungsi hati untuk mengevaluasi kesehatan hati dan organ-organ lain yang dapat mengandung enzim ini. Kadar serum glutamat oksalat transaminase (SGOT) dalam U/ml, indikator kerusakan hati.\n\n\nTryglicerides\nKadar trigliserida, indikator kesehatan metabolik.\n\n\nPlatelets\nJumlah trombosit per ml/1000, gangguan jumlah trombosit terkait dengan kerusakan hati.\n\n\nProthrombin\nProthrombin adalah sebuah protein yang terlibat dalam proses pembekuan darah. Ini adalah salah satu faktor pembekuan darah yang penting dan berperan dalam mengubah fibrinogen menjadi fibrin, suatu langkah kunci dalam pembentukan bekuan darah. Waktu protrombin dalam detik, indikator fungsi pembekuan darah.\n\n\nStage\nTahap atau tingkat keparahan sirosis hati pada saat pengamatan awal (1, 2, 3, atau 4) semakin mendekati 4 maka semakin parah."
  },
  {
    "objectID": "index.html#melakukan-pengambilan-dataset",
    "href": "index.html#melakukan-pengambilan-dataset",
    "title": "Quarto CRC Book",
    "section": "Melakukan pengambilan dataset",
    "text": "Melakukan pengambilan dataset\n\nimport pandas as pd\n\nurl = \"cirrhosis.csv\"\n\n# Mengimpor data ke dalam pandas DataFrame\ndf = pd.read_csv(url)\n\ndf\n\n\n\n\n\n\n\n\nID\nN_Days\nStatus\nDrug\nAge\nSex\nAscites\nHepatomegaly\nSpiders\nEdema\nBilirubin\nCholesterol\nAlbumin\nCopper\nAlk_Phos\nSGOT\nTryglicerides\nPlatelets\nProthrombin\nStage\n\n\n\n\n0\n1\n400\nD\nD-penicillamine\n21464\nF\nY\nY\nY\nY\n14.5\n261.0\n2.60\n156.0\n1718.0\n137.95\n172.0\n190.0\n12.2\n4.0\n\n\n1\n2\n4500\nC\nD-penicillamine\n20617\nF\nN\nY\nY\nN\n1.1\n302.0\n4.14\n54.0\n7394.8\n113.52\n88.0\n221.0\n10.6\n3.0\n\n\n2\n3\n1012\nD\nD-penicillamine\n25594\nM\nN\nN\nN\nS\n1.4\n176.0\n3.48\n210.0\n516.0\n96.10\n55.0\n151.0\n12.0\n4.0\n\n\n3\n4\n1925\nD\nD-penicillamine\n19994\nF\nN\nY\nY\nS\n1.8\n244.0\n2.54\n64.0\n6121.8\n60.63\n92.0\n183.0\n10.3\n4.0\n\n\n4\n5\n1504\nCL\nPlacebo\n13918\nF\nN\nY\nY\nN\n3.4\n279.0\n3.53\n143.0\n671.0\n113.15\n72.0\n136.0\n10.9\n3.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n413\n414\n681\nD\nNaN\n24472\nF\nNaN\nNaN\nNaN\nN\n1.2\nNaN\n2.96\nNaN\nNaN\nNaN\nNaN\n174.0\n10.9\n3.0\n\n\n414\n415\n1103\nC\nNaN\n14245\nF\nNaN\nNaN\nNaN\nN\n0.9\nNaN\n3.83\nNaN\nNaN\nNaN\nNaN\n180.0\n11.2\n4.0\n\n\n415\n416\n1055\nC\nNaN\n20819\nF\nNaN\nNaN\nNaN\nN\n1.6\nNaN\n3.42\nNaN\nNaN\nNaN\nNaN\n143.0\n9.9\n3.0\n\n\n416\n417\n691\nC\nNaN\n21185\nF\nNaN\nNaN\nNaN\nN\n0.8\nNaN\n3.75\nNaN\nNaN\nNaN\nNaN\n269.0\n10.4\n3.0\n\n\n417\n418\n976\nC\nNaN\n19358\nF\nNaN\nNaN\nNaN\nN\n0.7\nNaN\n3.29\nNaN\nNaN\nNaN\nNaN\n350.0\n10.6\n4.0\n\n\n\n\n418 rows × 20 columns\n\n\n\nDisini adalah data data dari Cirrhosis Patient Survival Prediction terdapat 19 fitur dan 1 label, untuk labelnya adalah status sebagai kategory dan prediksi pada seseorang, banyaknya data pada dataset tersebut adalah 418 data.\nLangkah yang saya lakukan dengan mengambil file penyimpanan saya lalu menggunakan import pandas untuk menampilkan tabel pada dataset."
  },
  {
    "objectID": "index.html#permasalahan-nan-pada-data",
    "href": "index.html#permasalahan-nan-pada-data",
    "title": "Quarto CRC Book",
    "section": "Permasalahan Nan pada data",
    "text": "Permasalahan Nan pada data\n\nmissing_values = df.isnull().sum()\n\n\nprint(\"Kolom dengan Missing Value:\")\nprint(missing_values[missing_values &gt; 0])\n\nKolom dengan Missing Value:\nDrug             106\nAscites          106\nHepatomegaly     106\nSpiders          106\nCholesterol      134\nCopper           108\nAlk_Phos         106\nSGOT             106\nTryglicerides    136\nPlatelets         11\nProthrombin        2\nStage              6\ndtype: int64\n\n\nJika kita lihat pada tabel terdaopat data yang nan atau missing value, disini saya melihat bahwa data integer dan categori sama sama terdapat missing value, jadi saya melakukan penyelesaian ini dengan terpisah :\n\n1. Missing value data bertype Integer dan Continuous\nyang saya lakukan ketika terjadinya missing value terhadap data type integer dan Continuous dengan menggunakan\nRumus Interpolate\n\\[\ny = y_1 + (x - x_1) \\times \\frac{{y_2 - y_1}}{{x_2 - x_1}}\n\\] - x1 dan y1 adalah nilai diatas x2 dan y2 (maksudnya ketika x2 dan y2 tersebut berada pada data ke 4 maka x1 dan y1 di data 3 )\n\nx2 dan y2 adalah nilai diatas Nan yang akan di interpolate dan dibawah nilai xi dan y1\nx Nilai yang akan diinterpolasi, dan kita ingin menemukan nilai y yang sesuai di antara dua titik data yang diketahui.\n\n\ndf.interpolate(method='linear', inplace=True)\n\ndf\n\n\n\n\n\n\n\n\nID\nN_Days\nStatus\nDrug\nAge\nSex\nAscites\nHepatomegaly\nSpiders\nEdema\nBilirubin\nCholesterol\nAlbumin\nCopper\nAlk_Phos\nSGOT\nTryglicerides\nPlatelets\nProthrombin\nStage\n\n\n\n\n0\n1\n400\nD\nD-penicillamine\n21464\nF\nY\nY\nY\nY\n14.5\n261.0\n2.60\n156.0\n1718.0\n137.95\n172.0\n190.0\n12.2\n4.0\n\n\n1\n2\n4500\nC\nD-penicillamine\n20617\nF\nN\nY\nY\nN\n1.1\n302.0\n4.14\n54.0\n7394.8\n113.52\n88.0\n221.0\n10.6\n3.0\n\n\n2\n3\n1012\nD\nD-penicillamine\n25594\nM\nN\nN\nN\nS\n1.4\n176.0\n3.48\n210.0\n516.0\n96.10\n55.0\n151.0\n12.0\n4.0\n\n\n3\n4\n1925\nD\nD-penicillamine\n19994\nF\nN\nY\nY\nS\n1.8\n244.0\n2.54\n64.0\n6121.8\n60.63\n92.0\n183.0\n10.3\n4.0\n\n\n4\n5\n1504\nCL\nPlacebo\n13918\nF\nN\nY\nY\nN\n3.4\n279.0\n3.53\n143.0\n671.0\n113.15\n72.0\n136.0\n10.9\n3.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n413\n414\n681\nD\nNaN\n24472\nF\nNaN\nNaN\nNaN\nN\n1.2\n576.0\n2.96\n186.0\n2115.0\n136.00\n149.0\n174.0\n10.9\n3.0\n\n\n414\n415\n1103\nC\nNaN\n14245\nF\nNaN\nNaN\nNaN\nN\n0.9\n576.0\n3.83\n186.0\n2115.0\n136.00\n149.0\n180.0\n11.2\n4.0\n\n\n415\n416\n1055\nC\nNaN\n20819\nF\nNaN\nNaN\nNaN\nN\n1.6\n576.0\n3.42\n186.0\n2115.0\n136.00\n149.0\n143.0\n9.9\n3.0\n\n\n416\n417\n691\nC\nNaN\n21185\nF\nNaN\nNaN\nNaN\nN\n0.8\n576.0\n3.75\n186.0\n2115.0\n136.00\n149.0\n269.0\n10.4\n3.0\n\n\n417\n418\n976\nC\nNaN\n19358\nF\nNaN\nNaN\nNaN\nN\n0.7\n576.0\n3.29\n186.0\n2115.0\n136.00\n149.0\n350.0\n10.6\n4.0\n\n\n\n\n418 rows × 20 columns\n\n\n\nFungsi interpolate dalam Pandas digunakan untuk mengisi nilai-nilai yang hilang atau yang hilang dalam suatu DataFrame atau Series dengan metode interpolasi. Dalam konteks fungsi ini, interpolasi mengacu pada metode pengisian nilai di antara titik data yang diketahui.\n\nmethod: Parameter ini menentukan metode interpolasi yang akan digunakan. Dalam kasus saya menggunakan method linear di mana nilai di antara dua titik data dikalkulasi sebagai garis lurus.\nmemilih inplace=True karena perubahan data data nantinya akan di operasikan dan diterapkan langsung pada objek, tanpa perlu menyimpan hasil operasi ke dalam variabel baru.\n\n\n\n2 Missing value dengan type data categori\nyang saya lakukan ketika terjadinya missing value terhadap data type categori dengan menggunakan\nrumus Mode imputation\n\\[\nMode=Nilai Yang Paling Sering Muncul Dalam Fitur Atau Kolom\n\\]\n\ndf['Drug'   ].fillna(df['Drug'].mode()[0], inplace=True)\ndf['Ascites'    ].fillna(df['Ascites'].mode()[0], inplace=True)\ndf['Hepatomegaly'   ].fillna(df['Hepatomegaly'].mode()[0], inplace=True)\ndf['Spiders'    ].fillna(df['Stage'].mode()[0], inplace=True)\ndf['Stage'  ].fillna(df['Stage'].mode()[0], inplace=True)\n\ndf\n\n\n\n\n\n\n\n\nID\nN_Days\nStatus\nDrug\nAge\nSex\nAscites\nHepatomegaly\nSpiders\nEdema\nBilirubin\nCholesterol\nAlbumin\nCopper\nAlk_Phos\nSGOT\nTryglicerides\nPlatelets\nProthrombin\nStage\n\n\n\n\n0\n1\n400\nD\nD-penicillamine\n21464\nF\nY\nY\nY\nY\n14.5\n261.0\n2.60\n156.0\n1718.0\n137.95\n172.0\n190.0\n12.2\n4.0\n\n\n1\n2\n4500\nC\nD-penicillamine\n20617\nF\nN\nY\nY\nN\n1.1\n302.0\n4.14\n54.0\n7394.8\n113.52\n88.0\n221.0\n10.6\n3.0\n\n\n2\n3\n1012\nD\nD-penicillamine\n25594\nM\nN\nN\nN\nS\n1.4\n176.0\n3.48\n210.0\n516.0\n96.10\n55.0\n151.0\n12.0\n4.0\n\n\n3\n4\n1925\nD\nD-penicillamine\n19994\nF\nN\nY\nY\nS\n1.8\n244.0\n2.54\n64.0\n6121.8\n60.63\n92.0\n183.0\n10.3\n4.0\n\n\n4\n5\n1504\nCL\nPlacebo\n13918\nF\nN\nY\nY\nN\n3.4\n279.0\n3.53\n143.0\n671.0\n113.15\n72.0\n136.0\n10.9\n3.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n413\n414\n681\nD\nD-penicillamine\n24472\nF\nN\nY\n3.0\nN\n1.2\n576.0\n2.96\n186.0\n2115.0\n136.00\n149.0\n174.0\n10.9\n3.0\n\n\n414\n415\n1103\nC\nD-penicillamine\n14245\nF\nN\nY\n3.0\nN\n0.9\n576.0\n3.83\n186.0\n2115.0\n136.00\n149.0\n180.0\n11.2\n4.0\n\n\n415\n416\n1055\nC\nD-penicillamine\n20819\nF\nN\nY\n3.0\nN\n1.6\n576.0\n3.42\n186.0\n2115.0\n136.00\n149.0\n143.0\n9.9\n3.0\n\n\n416\n417\n691\nC\nD-penicillamine\n21185\nF\nN\nY\n3.0\nN\n0.8\n576.0\n3.75\n186.0\n2115.0\n136.00\n149.0\n269.0\n10.4\n3.0\n\n\n417\n418\n976\nC\nD-penicillamine\n19358\nF\nN\nY\n3.0\nN\n0.7\n576.0\n3.29\n186.0\n2115.0\n136.00\n149.0\n350.0\n10.6\n4.0\n\n\n\n\n418 rows × 20 columns\n\n\n\ndisini diketahui pada dataset saya terdapat 5 fitur yang mengalami missing value, maka saya berasumsi untuk melakukan mode imputation dengan beralasan bahwa perhitungannya dimengerti karena dengan cara melihat nilai yang paling muncul kita dapatkan output untuk data Nan dan menggunakan mode tersebut tidak akan merusak dan mengubah nilai pada data yang lain jadi lebih aman\n\n\nKesalahan pada inputan Age (Umur)\nPada data tersebut terjadi kesalahan inputan pada salah satu fitur yaitu umur, yang dimana umur tersebut berupa puluhan ribu yang bisa dikatakan bagi kita tidak masuk akal seseorang mempunyai umur senilai puluhan ribu, maka saya modifikasi hanya fitur Age dengan menghapus 3 angka belakang atau saya bagi dengan 1000\n\ndf['Age'] = df['Age'] // 1000\ndf\n\n\n\n\n\n\n\n\nID\nN_Days\nStatus\nDrug\nAge\nSex\nAscites\nHepatomegaly\nSpiders\nEdema\nBilirubin\nCholesterol\nAlbumin\nCopper\nAlk_Phos\nSGOT\nTryglicerides\nPlatelets\nProthrombin\nStage\n\n\n\n\n0\n1\n400\nD\nD-penicillamine\n21\nF\nY\nY\nY\nY\n14.5\n261.0\n2.60\n156.0\n1718.0\n137.95\n172.0\n190.0\n12.2\n4.0\n\n\n1\n2\n4500\nC\nD-penicillamine\n20\nF\nN\nY\nY\nN\n1.1\n302.0\n4.14\n54.0\n7394.8\n113.52\n88.0\n221.0\n10.6\n3.0\n\n\n2\n3\n1012\nD\nD-penicillamine\n25\nM\nN\nN\nN\nS\n1.4\n176.0\n3.48\n210.0\n516.0\n96.10\n55.0\n151.0\n12.0\n4.0\n\n\n3\n4\n1925\nD\nD-penicillamine\n19\nF\nN\nY\nY\nS\n1.8\n244.0\n2.54\n64.0\n6121.8\n60.63\n92.0\n183.0\n10.3\n4.0\n\n\n4\n5\n1504\nCL\nPlacebo\n13\nF\nN\nY\nY\nN\n3.4\n279.0\n3.53\n143.0\n671.0\n113.15\n72.0\n136.0\n10.9\n3.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n413\n414\n681\nD\nD-penicillamine\n24\nF\nN\nY\n3.0\nN\n1.2\n576.0\n2.96\n186.0\n2115.0\n136.00\n149.0\n174.0\n10.9\n3.0\n\n\n414\n415\n1103\nC\nD-penicillamine\n14\nF\nN\nY\n3.0\nN\n0.9\n576.0\n3.83\n186.0\n2115.0\n136.00\n149.0\n180.0\n11.2\n4.0\n\n\n415\n416\n1055\nC\nD-penicillamine\n20\nF\nN\nY\n3.0\nN\n1.6\n576.0\n3.42\n186.0\n2115.0\n136.00\n149.0\n143.0\n9.9\n3.0\n\n\n416\n417\n691\nC\nD-penicillamine\n21\nF\nN\nY\n3.0\nN\n0.8\n576.0\n3.75\n186.0\n2115.0\n136.00\n149.0\n269.0\n10.4\n3.0\n\n\n417\n418\n976\nC\nD-penicillamine\n19\nF\nN\nY\n3.0\nN\n0.7\n576.0\n3.29\n186.0\n2115.0\n136.00\n149.0\n350.0\n10.6\n4.0\n\n\n\n\n418 rows × 20 columns"
  },
  {
    "objectID": "index.html#visualisasi-data",
    "href": "index.html#visualisasi-data",
    "title": "Quarto CRC Book",
    "section": "visualisasi data",
    "text": "visualisasi data\n\nvisual untuk mengetahui banyaknya masing masing jenis kelamin yang terkena penyakit\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(8, 8))\ndf['Sex'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90)\nplt.title('Pie Chart Jenis Kelamin Pasien')\nplt.show()\n\n\n\n\nDari visualisasi Pie Chart Jenis Kelamin Pasien, terlihat bahwa proporsi pasien perempuan (F) lebih dominan daripada pasien laki-laki (M). Kesimpulan ini dapat diambil dari sebaran data yang menunjukkan bahwa lebih banyak pasien yang dicatat dalam dataset memiliki jenis kelamin perempuan daripada jenis kelamin laki-laki.\n\n\nVisual tentang seberapa pengaruh Cirrhosis Patient pada umur tertent\n\nimport seaborn as sns\nplt.figure(figsize=(10, 6))\nsns.histplot(df['Age'], bins=30, kde=True)\nplt.title('Distribusi Umur Pasien')\nplt.xlabel('Umur')\nplt.ylabel('banyaknya pasien')\nplt.show()\n\nplt.figure(figsize=(10, 6))\nsns.boxplot(x='Age', y='Status', data=df)\nplt.title('Hubungan antara Umur dan Status Pasien')\nplt.xlabel('Status Pasien')\nplt.ylabel('Umur')\nplt.show()\n\n\n\n\n\n\n\n\nRentang Usia Remaja (17-20 tahun): Pada rentang usia ini, terlihat adanya peningkatan signifikan dalam Cirrhosis Patient . Hal ini dapat menunjukkan bahwa remaja dalam kelompok usia ini mungkin memiliki faktor risiko tertentu yang berkontribusi pada prediksi penyakit hati. Status Pasien pada Usia 12-15 Tahun:\nPrediksi status C (censored) yang lebih dominan pada kelompok usia 12-15 tahun mungkin menunjukkan adanya kecenderungan untuk peristiwa yang tidak dapat diamati secara penuh. Ini bisa disebabkan oleh data yang tidak lengkap atau informasi yang tidak tersedia setelah periode pengamatan tertentu. Status Pasien pada Usia 14-20 Tahun:\nRentang usia 14-20 tahun menunjukkan kecenderungan prediksi status CL (censored karena transplantasi hati). Ini mungkin menandakan bahwa di dalam kelompok ini, pasien memiliki perawatan atau intervensi medis tertentu yang menyebabkan data pengamatan terhenti, seperti transplantasi hati. Status Pasien pada Usia 16-22 Tahun:\nPada usia ini, prediksi status D (kematian) mulai muncul lebih sering. Hal ini bisa menunjukkan tingkat keparahan penyakit atau faktor risiko tambahan yang dapat memengaruhi hasil pasien pada kelompok usia tersebut."
  },
  {
    "objectID": "index.html#informasi-pada-label-dataset",
    "href": "index.html#informasi-pada-label-dataset",
    "title": "Quarto CRC Book",
    "section": "Informasi pada label dataset",
    "text": "Informasi pada label dataset\n\ntarget_counts = df['Status'].value_counts()\njumlah_kategori = df['Status'].nunique()\n\nprint(\"Jumlah kategori pada target:\", jumlah_kategori)\nprint(target_counts)\n\nJumlah kategori pada target: 3\nStatus\nC     232\nD     161\nCL     25\nName: count, dtype: int64\n\n\nDisini pada label mempunya 3 kelas yaitu: - C (Censored): Artinya pasien tidak mengalami peristiwa akhir atau mati selama periode pengamatan. Data pasien tersebut “censored” karena tidak ada informasi akhir yang tersedia. - CL (Censored due to liver tx) Artinya pasien tidak mengalami peristiwa akhir karena censored dan peristiwa censored tersebut terjadi karena pasien menjalani transplantasi hati. - D (Death): Artinya pasien mengalami kematian sebagai peristiwa akhir selama periode pengamatan\ndiatas bahwa data terbanyak yaitu categori C\nPerbedaan C dan CL yaitu C keterangannya tidak peristiwa akhir atau mati tapi tidak melakukan transplantasi hati sedangkan CL juga tidak ada tanda tanda peristiwa akhir tetapi harus menjalankan transplantasi hati untuk menggantikan hati yang rusak\n\nX = df.drop(['Status','ID'], axis=1)\ny = df[\"Status\"]\n\nMemisahkan antara fitur dengan label"
  },
  {
    "objectID": "index.html#seleksi-fitur",
    "href": "index.html#seleksi-fitur",
    "title": "Quarto CRC Book",
    "section": "Seleksi fitur",
    "text": "Seleksi fitur\nsebelum melakukan preprocessing data alangkah baiknya untuk menyeleksikan fitur fitur yang menurut kita adalah fitur yang tidak berpengaruh terhadap dataset dan mengurangi beban dataset agar tidak menyebabkan overfitting\n\nX['Drug'] = X['Drug'].astype('category').cat.codes\nX['Ascites'] = X['Ascites'].astype('category').cat.codes\nX['Hepatomegaly'] = X['Hepatomegaly'].astype('category').cat.codes\nX['Spiders'] = X['Spiders'].astype('category').cat.codes\nX['Stage'] = X['Stage'].astype('category').cat.codes\nX['Sex'] = X['Sex'].astype('category').cat.codes\nX['Edema'] = X['Edema'].astype('category').cat.codes\nfrom sklearn.feature_selection import SelectKBest, f_classif\n\n\nselector = SelectKBest(score_func=f_classif, k=18)  \nselector.fit(X, y)\n\nselected_features = selector.get_support(indices=True)\n\nfeature_names = X.columns\n\n\nselected_feature_names = [feature_names[i] for i in selected_features]\n\nscores = selector.scores_[selected_features]\n\n\nplt.figure(figsize=(10, 6))\nplt.bar(selected_feature_names, scores, color='skyblue')\nplt.xlabel('Fitur')\nplt.ylabel('Skor Statistik')\nplt.title('Skor Statistik untuk Fitur-Fitur Terpilih')\nplt.xticks(rotation=45)\nplt.tight_layout()\n\n# Menampilkan grafik\nplt.show()\n\n\n\n\nDisini saya menggunakan sckit learn untuk melakukan selection pada fitur - yang pertama saya menentukan banyaknya fitur terdapat N = banyak fitur, fitur yang ada didataset adalah 19 fitur - Jumlah fitur terbaik yang terpilih disesuaikan dengan nilai K di atas - ambil data data pada setiap fitur menggunakan funtion colomns dan nama pada fitur akan dimasukan kedalam selected_feature_names - lalu proses melakukan perhitungan statistik ANOVA dengan rumus\n\\[\nF = \\frac{MSB}{MSW}\n\\] MSB atau mean square antar kelompok (mean square between groups). dapat dari rumus ini :\n\\[\nMSB = \\frac{\\sum_{i=1}^{k} n_i (\\bar{X}_i - \\bar{X}_{\\text{total}})^2}{k - 1}\n\\] dan MSW atau mean square dalam kelompok (mean square within groups)\n\\[\nMSW = \\frac{\\sum_{i=1}^{k} \\sum_{j=1}^{n_i} (X_{ij} - \\bar{X}_i)^2}{N - k}\n\\] Untuk hasil akhirnya saya menghapus 8 fitur yang menurut saya tidak akan berpengaruh terhadap dataset saya\n\nX = df.drop(['N_Days','ID','Status','Drug','Sex','Spiders','Cholesterol','Tryglicerides','Platelets'], axis=1)\nX\n\n\n\n\n\n\n\n\nAge\nAscites\nHepatomegaly\nEdema\nBilirubin\nAlbumin\nCopper\nAlk_Phos\nSGOT\nProthrombin\nStage\n\n\n\n\n0\n21\nY\nY\nY\n14.5\n2.60\n156.0\n1718.0\n137.95\n12.2\n4.0\n\n\n1\n20\nN\nY\nN\n1.1\n4.14\n54.0\n7394.8\n113.52\n10.6\n3.0\n\n\n2\n25\nN\nN\nS\n1.4\n3.48\n210.0\n516.0\n96.10\n12.0\n4.0\n\n\n3\n19\nN\nY\nS\n1.8\n2.54\n64.0\n6121.8\n60.63\n10.3\n4.0\n\n\n4\n13\nN\nY\nN\n3.4\n3.53\n143.0\n671.0\n113.15\n10.9\n3.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n413\n24\nN\nY\nN\n1.2\n2.96\n186.0\n2115.0\n136.00\n10.9\n3.0\n\n\n414\n14\nN\nY\nN\n0.9\n3.83\n186.0\n2115.0\n136.00\n11.2\n4.0\n\n\n415\n20\nN\nY\nN\n1.6\n3.42\n186.0\n2115.0\n136.00\n9.9\n3.0\n\n\n416\n21\nN\nY\nN\n0.8\n3.75\n186.0\n2115.0\n136.00\n10.4\n3.0\n\n\n417\n19\nN\nY\nN\n0.7\n3.29\n186.0\n2115.0\n136.00\n10.6\n4.0\n\n\n\n\n418 rows × 11 columns"
  },
  {
    "objectID": "index.html#mengganti-categori-menjadi-numerik",
    "href": "index.html#mengganti-categori-menjadi-numerik",
    "title": "Quarto CRC Book",
    "section": "Mengganti categori menjadi numerik",
    "text": "Mengganti categori menjadi numerik\nSebelum melakukan preprosessing pada dataset saya diketahui memiliki categori yang harus diganti menjadi numerik, maka saya gunakan code seperti dibawah :\n\nX['Ascites'] = X['Ascites'].astype('category').cat.codes\nX['Hepatomegaly'] = X['Hepatomegaly'].astype('category').cat.codes\nX['Edema'] = X['Edema'].astype('category').cat.codes\nX\n\n\n\n\n\n\n\n\nAge\nAscites\nHepatomegaly\nEdema\nBilirubin\nAlbumin\nCopper\nAlk_Phos\nSGOT\nProthrombin\nStage\n\n\n\n\n0\n21\n1\n1\n2\n14.5\n2.60\n156.0\n1718.0\n137.95\n12.2\n4.0\n\n\n1\n20\n0\n1\n0\n1.1\n4.14\n54.0\n7394.8\n113.52\n10.6\n3.0\n\n\n2\n25\n0\n0\n1\n1.4\n3.48\n210.0\n516.0\n96.10\n12.0\n4.0\n\n\n3\n19\n0\n1\n1\n1.8\n2.54\n64.0\n6121.8\n60.63\n10.3\n4.0\n\n\n4\n13\n0\n1\n0\n3.4\n3.53\n143.0\n671.0\n113.15\n10.9\n3.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n413\n24\n0\n1\n0\n1.2\n2.96\n186.0\n2115.0\n136.00\n10.9\n3.0\n\n\n414\n14\n0\n1\n0\n0.9\n3.83\n186.0\n2115.0\n136.00\n11.2\n4.0\n\n\n415\n20\n0\n1\n0\n1.6\n3.42\n186.0\n2115.0\n136.00\n9.9\n3.0\n\n\n416\n21\n0\n1\n0\n0.8\n3.75\n186.0\n2115.0\n136.00\n10.4\n3.0\n\n\n417\n19\n0\n1\n0\n0.7\n3.29\n186.0\n2115.0\n136.00\n10.6\n4.0\n\n\n\n\n418 rows × 11 columns\n\n\n\ndiatas terdapat cara untuk menggantikan sebuah type kategori menjadi numerik, terdapat fungsi yang saya pakai :\n\nastype(‘category’) , funtion tersebut untuk memberi tahu bahwa pada fitur tersebut adalah type category\ncat.codes untuk mengubah category menjadi numerik, Bilangan bulat yang diberikan dimulai dari 0 dan terus bertambah seiring dengan munculnya nilai kategori yang baru. contohnya pada fitur Sex mempunyai 2 category yaitu wanita dan lelaki, maka wanita akan diganti menjadi 0 dan lelaki akan menjadi 1"
  },
  {
    "objectID": "index.html#split-data-menjadi-train-data-dan-test-data",
    "href": "index.html#split-data-menjadi-train-data-dan-test-data",
    "title": "Quarto CRC Book",
    "section": "Split data menjadi train data dan test data",
    "text": "Split data menjadi train data dan test data\ntrain_test_split adalah suatu fungsi dalam library scikit-learn yang digunakan untuk membagi dataset menjadi dua set, yaitu set pelatihan (training set) dan set pengujian (testing set). Pemisahan ini bertujuan untuk melakukan pelatihan model pada set pelatihan dan menguji kinerja model pada set pengujian. Fungsi ini sangat umum digunakan dalam proses machine learning untuk menghindari overfitting dan mengevaluasi kemampuan generalisasi dari model yang telah dilatih\n\ntest_size (opsional): Menentukan ukuran set pengujian sebagai proporsi dari seluruh dataset. Nilai ini bisa berupa pecahan (misalnya, 0.2 untuk 20%) atau bilangan bulat yang menyatakan jumlah sampel yang akan ditempatkan di set pengujian.\nrandom_state (opsional): Digunakan untuk mengontrol randomization selama pembagian dataset. Jika nilai ini diberikan, pemisahan dataset akan tetap konsisten setiap kali fungsi ini dijalankan"
  },
  {
    "objectID": "index.html#normalisasi-data",
    "href": "index.html#normalisasi-data",
    "title": "Quarto CRC Book",
    "section": "Normalisasi data",
    "text": "Normalisasi data\nSetelah melakukan understanding data maka melakukan preprocessing yang dimana data akan di jadikan antara 0 sampai 1\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import MinMaxScaler\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = MinMaxScaler()\nX_train_scaler = scaler.fit_transform(X_train)\nX_test_scaler = scaler.transform(X_test)\nx = pd.DataFrame(X_train,columns=X.columns)\nx\n\n\n\n\n\n\n\n\nAge\nAscites\nHepatomegaly\nEdema\nBilirubin\nAlbumin\nCopper\nAlk_Phos\nSGOT\nProthrombin\nStage\n\n\n\n\n336\n20\n0\n1\n0\n1.8\n3.64\n186.0\n2115.0\n136.00\n10.0\n3.0\n\n\n31\n19\n0\n1\n0\n1.8\n3.34\n101.0\n7277.0\n82.56\n10.6\n4.0\n\n\n84\n17\n0\n1\n0\n2.1\n3.48\n58.0\n2045.0\n89.90\n11.5\n4.0\n\n\n287\n17\n0\n1\n1\n8.7\n3.89\n107.0\n637.0\n117.00\n9.6\n2.0\n\n\n317\n15\n0\n1\n0\n0.7\n3.68\n186.0\n2115.0\n136.00\n9.5\n2.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n71\n11\n0\n0\n0\n0.5\n3.54\n51.0\n1243.0\n122.45\n10.0\n3.0\n\n\n106\n22\n0\n0\n0\n0.6\n4.03\n10.0\n648.0\n71.30\n17.1\n1.0\n\n\n270\n18\n0\n1\n0\n1.0\n3.50\n94.0\n955.0\n111.00\n9.7\n3.0\n\n\n348\n19\n0\n1\n0\n1.4\n3.82\n186.0\n2115.0\n136.00\n10.3\n2.0\n\n\n102\n17\n1\n1\n2\n2.5\n3.67\n57.0\n1273.0\n119.35\n11.1\n4.0\n\n\n\n\n334 rows × 11 columns\n\n\n\ndengan menggunakan minmaxScaller untuk menormalisasi data , dan menggunakan train_test_split untuk mendapatkan data training dan data testing\nrumus MinmaxScaler:\n\\[\n\\text{Scaled Value} = \\frac{\\text{Original Value} - \\text{Min}}{\\text{Max} - \\text{Min}}\n\\] - Original Value adalah nilai asli dari fitur.\n\nMin adalah nilai minimum dari fitur.\nMax adalah nilai maksimum dari fitur.\n\n\nfit_transform Fungsinya ini menghitung parameter normalisasi dari dataset (seperti nilai minimum dan maksimum) dan kemudian mengaplikasikan normalisasi pada dataset tersebut. Fungsi ini berguna untuk menghitung parameter normalisasi berdasarkan data pelatihan dan sekaligus menerapkan normalisasi tersebut.\nSetelah kita telah menggunakan fit_transform pada data pelatihan, kita dapat menggunakan metode transform pada data pengujian (dan data lainnya yang ingin dinormalisasi) menggunakan parameter normalisasi yang telah dihitung sebelumnya. Metode ini hanya melakukan normalisasi tanpa perlu menghitung parameter normalisasi lagi."
  },
  {
    "objectID": "index.html#melatih-model-menggunakan-random-forest",
    "href": "index.html#melatih-model-menggunakan-random-forest",
    "title": "Quarto CRC Book",
    "section": "Melatih Model menggunakan Random Forest",
    "text": "Melatih Model menggunakan Random Forest\nRandom Forest adalah sebuah algoritma machine learning yang digunakan untuk tugas klasifikasi, regresi, dan pengurangan dimensi. Ini merupakan jenis algoritma ensemble, yang menggabungkan beberapa model untuk meningkatkan kinerja dan kestabilan prediksi. Algoritma Random Forest membangun beberapa pohon keputusan selama pelatihan dan menggabungkan hasil prediksi dari pohon-pohon tersebut untuk membuat prediksi yang lebih akurat dan stabil\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n# Buat model Random Forest\nrandom_forest_model = RandomForestClassifier(n_estimators=100)\n# Latih model\nrandom_forest_model.fit(X_train, y_train)\n# Prediksi dengan model\nrandom_forest_predictions = random_forest_model.predict(X_test)\n# Evaluasi kinerja model\nrandom_forest_accuracy = accuracy_score(y_test, random_forest_predictions)\n\nalasan mengapa menggunakan Random Forest Dengan mempertimbangkan acak dan menggunakan banyak pohon, Random Forest dapat mengurangi risiko overfitting pada data pelatihan.\nrumus Random forest\n\nPrediksi pada Pohon Keputusan \\[\n\\text{Prediction}_{\\text{tree}} = \\text{MajorityClass}(\\text{Samples in Leaf})\n\\]\nAggregasi Prediksi dari Semua Pohon (Klasifikasi) \\[\n\\text{Final Prediction}_{\\text{RF}} = \\text{MajorityClass}(\\text{Predictions from all Trees})\n\\]\nAggregasi Prediksi dari Semua Pohon (Regresi) \\[\n\\text{Final Prediction}_{\\text{RF}} = \\text{Average}(\\text{Predictions from all Trees})\n\\]"
  },
  {
    "objectID": "index.html#melatih-data-menggunakan-logistic-regression",
    "href": "index.html#melatih-data-menggunakan-logistic-regression",
    "title": "Quarto CRC Book",
    "section": "Melatih data menggunakan Logistic Regression",
    "text": "Melatih data menggunakan Logistic Regression\nLogistic Regression (Regresi Logistik) adalah algoritma machine learning yang digunakan untuk tugas klasifikasi. Meskipun memiliki kata “regresi” dalam namanya, logistic regression sebenarnya digunakan untuk masalah klasifikasi biner, di mana tujuannya adalah memprediksi kelas target yang memiliki dua kemungkinan nilai (biasanya 0 atau 1).\n\\[\nP(Y=1) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\ldots + \\beta_n X_n)}}\n\\]\n\nP(Y=1) adalah probabilitas kejadian\nY sama dengan 1.\ne adalah basis logaritma natural.\nb adalah bobot .\nX adalah data .\n\n\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\n\n# Latih model\nmodel.fit(X_train_scaler, y_train)\n\n# Prediksi dengan model\nlogistic_regression_predictions = model.predict(X_test)\n\n# Evaluasi kinerja model\nlogistic_regression_accuracy = accuracy_score(y_test, logistic_regression_predictions)\n\n/cloud/python/lib/python3.8/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n  warnings.warn("
  },
  {
    "objectID": "index.html#melatih-data-menggunakan-percepton",
    "href": "index.html#melatih-data-menggunakan-percepton",
    "title": "Quarto CRC Book",
    "section": "Melatih data menggunakan Percepton",
    "text": "Melatih data menggunakan Percepton\nPerceptron adalah model dasar dalam machine learning yang digunakan untuk tugas klasifikasi biner. Perceptron dirancang untuk memodelkan neuron dalam otak manusia dan dapat digunakan untuk memisahkan dua kelas dengan menarik garis pemisah linier. Namun, perceptron memiliki keterbatasan dan biasanya digunakan sebagai dasar untuk model neural network yang lebih kompleks.\n\\[\n\\text{Output} = \\begin{cases}\n1 & \\text{jika } \\sum_{i=1}^{n} w_i x_i + b &gt; 0 \\\\\n0 & \\text{lainnya}\n\\end{cases}\n\\]\n\nfrom sklearn.linear_model import Perceptron, SGDClassifier\n# Buat model Perceptron\nperceptron_model = Perceptron(max_iter=1000, random_state=42)\n\n# Latih model Perceptron\nperceptron_model.fit(X_train_scaler, y_train)\n\n# Prediksi dengan model Perceptron\nperceptron_predictions = perceptron_model.predict(X_test)\n\n# Evaluasi kinerja model Perceptron\nperceptron_accuracy = accuracy_score(y_test, perceptron_predictions)\n\n/cloud/python/lib/python3.8/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but Perceptron was fitted without feature names\n  warnings.warn("
  },
  {
    "objectID": "index.html#melatih-data-menggunakan-jaringan-saraf-tiruan",
    "href": "index.html#melatih-data-menggunakan-jaringan-saraf-tiruan",
    "title": "Quarto CRC Book",
    "section": "Melatih data menggunakan Jaringan Saraf Tiruan",
    "text": "Melatih data menggunakan Jaringan Saraf Tiruan\nJaringan Saraf Tiruan (JST) atau Neural Networks adalah bagian integral dari machine learning. Neural networks terinspirasi oleh struktur dan fungsi otak manusia dan dapat digunakan untuk menangani tugas-tugas kompleks seperti klasifikasi, regresi, pengenalan pola, dan bahkan pembelajaran tugas-tugas yang lebih kompleks\n\nfrom sklearn.neural_network import MLPClassifier\nneural_network_model = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=1000, random_state=42)\n\n# Latih model\nneural_network_model.fit(X_train_scaler, y_train)\n\n# Prediksi dengan model\nneural_network_predictions = neural_network_model.predict(X_test)\n\n# Evaluasi kinerja model\nneural_network_accuracy = accuracy_score(y_test, neural_network_predictions)\n\n/cloud/python/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/cloud/python/lib/python3.8/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n  warnings.warn("
  },
  {
    "objectID": "index.html#melatih-model-menggunakan-decision-tree",
    "href": "index.html#melatih-model-menggunakan-decision-tree",
    "title": "Quarto CRC Book",
    "section": "Melatih Model menggunakan decision tree",
    "text": "Melatih Model menggunakan decision tree\nDecision tree (pohon keputusan) adalah model prediktif yang digunakan dalam machine learning dan data mining. Model ini mengambil bentuk pohon dengan setiap simpul (node) yang mewakili keputusan atau pengujian terhadap suatu fitur, cabang (branch) yang mengarah ke simpul lainnya, dan daun (leaf) yang memberikan hasil atau prediksi. Decision tree digunakan untuk tugas klasifikasi dan regresi.\n\\[\n\\begin{equation}\n\\text{Jika } X_i \\leq T \\text{ maka cabang kiri, else cabang kanan}\n\\end{equation}\n\\]\n\nfrom sklearn.tree import DecisionTreeClassifier\ndecision_tree_model = DecisionTreeClassifier()\n# Latih model\ndecision_tree_model.fit(X_train, y_train)\n# Prediksi dengan model\ndecision_tree_predictions = decision_tree_model.predict(X_test)\n# Evaluasi kinerja model\ndecision_tree_accuracy = accuracy_score(y_test, decision_tree_predictions)"
  }
]